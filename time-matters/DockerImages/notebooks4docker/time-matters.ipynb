{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "<b><center><font size=\"4\">Time Matters</font></center></b>\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Developed by: [Ricardo Campos](http://www.ccc.ipt.pt/~ricardo)\n",
    "\n",
    "[Home](http://www.ccc.ipt.pt/~ricardo/TemporalTaggers/)\n",
    "<br>\n",
    "\n",
    "<p><a href=\"3time-matters.ipynb\" title=\"Download Notebook\" download><img src=\"../images/download.jpg\" align = \"left\" width=\"50\" height=\"50\" alt=\"Download Notebook\"></a></p>\n",
    "<p>&nbsp;</p>\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Time-Matters\" data-toc-modified-id=\"Time-Matters-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Time-Matters</a></span><ul class=\"toc-item\"><li><span><a href=\"#What-is-Time-Matters?\" data-toc-modified-id=\"What-is-Time-Matters?-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>What is Time-Matters?</a></span></li><li><span><a href=\"#Who-developed-this-package?\" data-toc-modified-id=\"Who-developed-this-package?-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>Who developed this package?</a></span></li><li><span><a href=\"#Rationale\" data-toc-modified-id=\"Rationale-1.3\"><span class=\"toc-item-num\">1.3&nbsp;&nbsp;</span>Rationale</a></span></li><li><span><a href=\"#How-does-it-works?\" data-toc-modified-id=\"How-does-it-works?-1.4\"><span class=\"toc-item-num\">1.4&nbsp;&nbsp;</span>How does it works?</a></span></li><li><span><a href=\"#Where-can-I-find-Time-Matters?\" data-toc-modified-id=\"Where-can-I-find-Time-Matters?-1.5\"><span class=\"toc-item-num\">1.5&nbsp;&nbsp;</span>Where can I find Time-Matters?</a></span></li></ul></li><li><span><a href=\"#Package\" data-toc-modified-id=\"Package-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Package</a></span><ul class=\"toc-item\"><li><span><a href=\"#Extracting-Relevant-Dates-from-Single-Documents\" data-toc-modified-id=\"Extracting-Relevant-Dates-from-Single-Documents-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Extracting Relevant Dates from Single Documents</a></span><ul class=\"toc-item\"><li><span><a href=\"#Usage-(Python)\" data-toc-modified-id=\"Usage-(Python)-2.1.1\"><span class=\"toc-item-num\">2.1.1&nbsp;&nbsp;</span>Usage (Python)</a></span><ul class=\"toc-item\"><li><span><a href=\"#Score\" data-toc-modified-id=\"Score-2.1.1.1\"><span class=\"toc-item-num\">2.1.1.1&nbsp;&nbsp;</span>Score</a></span><ul class=\"toc-item\"><li><span><a href=\"#ByDoc\" data-toc-modified-id=\"ByDoc-2.1.1.1.1\"><span class=\"toc-item-num\">2.1.1.1.1&nbsp;&nbsp;</span>ByDoc</a></span></li><li><span><a href=\"#BySentence\" data-toc-modified-id=\"BySentence-2.1.1.1.2\"><span class=\"toc-item-num\">2.1.1.1.2&nbsp;&nbsp;</span>BySentence</a></span></li></ul></li><li><span><a href=\"#Temporal-Expressions\" data-toc-modified-id=\"Temporal-Expressions-2.1.1.2\"><span class=\"toc-item-num\">2.1.1.2&nbsp;&nbsp;</span>Temporal Expressions</a></span></li><li><span><a href=\"#Relevant-Keywords\" data-toc-modified-id=\"Relevant-Keywords-2.1.1.3\"><span class=\"toc-item-num\">2.1.1.3&nbsp;&nbsp;</span>Relevant Keywords</a></span></li><li><span><a href=\"#Text-Normalized\" data-toc-modified-id=\"Text-Normalized-2.1.1.4\"><span class=\"toc-item-num\">2.1.1.4&nbsp;&nbsp;</span>Text Normalized</a></span></li><li><span><a href=\"#Text-Tokens\" data-toc-modified-id=\"Text-Tokens-2.1.1.5\"><span class=\"toc-item-num\">2.1.1.5&nbsp;&nbsp;</span>Text Tokens</a></span></li><li><span><a href=\"#Sentences-Normalized\" data-toc-modified-id=\"Sentences-Normalized-2.1.1.6\"><span class=\"toc-item-num\">2.1.1.6&nbsp;&nbsp;</span>Sentences Normalized</a></span></li><li><span><a href=\"#Sentences-Tokens\" data-toc-modified-id=\"Sentences-Tokens-2.1.1.7\"><span class=\"toc-item-num\">2.1.1.7&nbsp;&nbsp;</span>Sentences Tokens</a></span></li><li><span><a href=\"#Optional-Parameters\" data-toc-modified-id=\"Optional-Parameters-2.1.1.8\"><span class=\"toc-item-num\">2.1.1.8&nbsp;&nbsp;</span>Optional Parameters</a></span><ul class=\"toc-item\"><li><span><a href=\"#Temporal-Tagger\" data-toc-modified-id=\"Temporal-Tagger-2.1.1.8.1\"><span class=\"toc-item-num\">2.1.1.8.1&nbsp;&nbsp;</span>Temporal Tagger</a></span></li><li><span><a href=\"#Time-Matters\" data-toc-modified-id=\"Time-Matters-2.1.1.8.2\"><span class=\"toc-item-num\">2.1.1.8.2&nbsp;&nbsp;</span>Time Matters</a></span></li></ul></li><li><span><a href=\"#Debug\" data-toc-modified-id=\"Debug-2.1.1.9\"><span class=\"toc-item-num\">2.1.1.9&nbsp;&nbsp;</span>Debug</a></span><ul class=\"toc-item\"><li><span><a href=\"#Inverted-Index\" data-toc-modified-id=\"Inverted-Index-2.1.1.9.1\"><span class=\"toc-item-num\">2.1.1.9.1&nbsp;&nbsp;</span>Inverted Index</a></span></li><li><span><a href=\"#Dice-Matrix\" data-toc-modified-id=\"Dice-Matrix-2.1.1.9.2\"><span class=\"toc-item-num\">2.1.1.9.2&nbsp;&nbsp;</span>Dice Matrix</a></span></li><li><span><a href=\"#Execution-Time\" data-toc-modified-id=\"Execution-Time-2.1.1.9.3\"><span class=\"toc-item-num\">2.1.1.9.3&nbsp;&nbsp;</span>Execution Time</a></span></li></ul></li></ul></li><li><span><a href=\"#Usage-(Command-Line)\" data-toc-modified-id=\"Usage-(Command-Line)-2.1.2\"><span class=\"toc-item-num\">2.1.2&nbsp;&nbsp;</span>Usage (Command Line)</a></span></li></ul></li><li><span><a href=\"#Extracting-Relevant-Dates-from-Multiple-Documents\" data-toc-modified-id=\"Extracting-Relevant-Dates-from-Multiple-Documents-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Extracting Relevant Dates from Multiple Documents</a></span><ul class=\"toc-item\"><li><span><a href=\"#Usage-(Python)\" data-toc-modified-id=\"Usage-(Python)-2.2.1\"><span class=\"toc-item-num\">2.2.1&nbsp;&nbsp;</span>Usage (Python)</a></span><ul class=\"toc-item\"><li><span><a href=\"#Score\" data-toc-modified-id=\"Score-2.2.1.1\"><span class=\"toc-item-num\">2.2.1.1&nbsp;&nbsp;</span>Score</a></span><ul class=\"toc-item\"><li><span><a href=\"#ByCorpus\" data-toc-modified-id=\"ByCorpus-2.2.1.1.1\"><span class=\"toc-item-num\">2.2.1.1.1&nbsp;&nbsp;</span>ByCorpus</a></span></li><li><span><a href=\"#ByDoc\" data-toc-modified-id=\"ByDoc-2.2.1.1.2\"><span class=\"toc-item-num\">2.2.1.1.2&nbsp;&nbsp;</span>ByDoc</a></span></li><li><span><a href=\"#ByDocSentence\" data-toc-modified-id=\"ByDocSentence-2.2.1.1.3\"><span class=\"toc-item-num\">2.2.1.1.3&nbsp;&nbsp;</span>ByDocSentence</a></span></li></ul></li><li><span><a href=\"#Temporal-Expressions\" data-toc-modified-id=\"Temporal-Expressions-2.2.1.2\"><span class=\"toc-item-num\">2.2.1.2&nbsp;&nbsp;</span>Temporal Expressions</a></span></li><li><span><a href=\"#Relevant-Keywords\" data-toc-modified-id=\"Relevant-Keywords-2.2.1.3\"><span class=\"toc-item-num\">2.2.1.3&nbsp;&nbsp;</span>Relevant Keywords</a></span></li><li><span><a href=\"#Text-Normalized\" data-toc-modified-id=\"Text-Normalized-2.2.1.4\"><span class=\"toc-item-num\">2.2.1.4&nbsp;&nbsp;</span>Text Normalized</a></span></li><li><span><a href=\"#Text-Tokens\" data-toc-modified-id=\"Text-Tokens-2.2.1.5\"><span class=\"toc-item-num\">2.2.1.5&nbsp;&nbsp;</span>Text Tokens</a></span></li><li><span><a href=\"#Sentences-Normalized\" data-toc-modified-id=\"Sentences-Normalized-2.2.1.6\"><span class=\"toc-item-num\">2.2.1.6&nbsp;&nbsp;</span>Sentences Normalized</a></span></li><li><span><a href=\"#Sentences-Tokens\" data-toc-modified-id=\"Sentences-Tokens-2.2.1.7\"><span class=\"toc-item-num\">2.2.1.7&nbsp;&nbsp;</span>Sentences Tokens</a></span></li><li><span><a href=\"#Optional-Parameters\" data-toc-modified-id=\"Optional-Parameters-2.2.1.8\"><span class=\"toc-item-num\">2.2.1.8&nbsp;&nbsp;</span>Optional Parameters</a></span><ul class=\"toc-item\"><li><span><a href=\"#Temporal-Tagger\" data-toc-modified-id=\"Temporal-Tagger-2.2.1.8.1\"><span class=\"toc-item-num\">2.2.1.8.1&nbsp;&nbsp;</span>Temporal Tagger</a></span></li><li><span><a href=\"#Time-Matters\" data-toc-modified-id=\"Time-Matters-2.2.1.8.2\"><span class=\"toc-item-num\">2.2.1.8.2&nbsp;&nbsp;</span>Time Matters</a></span></li></ul></li><li><span><a href=\"#Debug\" data-toc-modified-id=\"Debug-2.2.1.9\"><span class=\"toc-item-num\">2.2.1.9&nbsp;&nbsp;</span>Debug</a></span><ul class=\"toc-item\"><li><span><a href=\"#Inverted-Index\" data-toc-modified-id=\"Inverted-Index-2.2.1.9.1\"><span class=\"toc-item-num\">2.2.1.9.1&nbsp;&nbsp;</span>Inverted Index</a></span></li><li><span><a href=\"#Dice-Matrix\" data-toc-modified-id=\"Dice-Matrix-2.2.1.9.2\"><span class=\"toc-item-num\">2.2.1.9.2&nbsp;&nbsp;</span>Dice Matrix</a></span></li><li><span><a href=\"#Execution-Time\" data-toc-modified-id=\"Execution-Time-2.2.1.9.3\"><span class=\"toc-item-num\">2.2.1.9.3&nbsp;&nbsp;</span>Execution Time</a></span></li></ul></li></ul></li><li><span><a href=\"#Cli---Command-Line-Interface\" data-toc-modified-id=\"Cli---Command-Line-Interface-2.2.2\"><span class=\"toc-item-num\">2.2.2&nbsp;&nbsp;</span>Cli - Command Line Interface</a></span></li></ul></li><li><span><a href=\"#API\" data-toc-modified-id=\"API-2.3\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>API</a></span><ul class=\"toc-item\"><li><span><a href=\"#apidocs\" data-toc-modified-id=\"apidocs-2.3.1\"><span class=\"toc-item-num\">2.3.1&nbsp;&nbsp;</span>apidocs</a></span></li><li><span><a href=\"#Code---Single-Doc\" data-toc-modified-id=\"Code---Single-Doc-2.3.2\"><span class=\"toc-item-num\">2.3.2&nbsp;&nbsp;</span>Code - Single Doc</a></span><ul class=\"toc-item\"><li><span><a href=\"#rule-based\" data-toc-modified-id=\"rule-based-2.3.2.1\"><span class=\"toc-item-num\">2.3.2.1&nbsp;&nbsp;</span>rule-based</a></span><ul class=\"toc-item\"><li><span><a href=\"#ByDoc\" data-toc-modified-id=\"ByDoc-2.3.2.1.1\"><span class=\"toc-item-num\">2.3.2.1.1&nbsp;&nbsp;</span>ByDoc</a></span></li><li><span><a href=\"#BySentence\" data-toc-modified-id=\"BySentence-2.3.2.1.2\"><span class=\"toc-item-num\">2.3.2.1.2&nbsp;&nbsp;</span>BySentence</a></span></li></ul></li><li><span><a href=\"#Heideltime\" data-toc-modified-id=\"Heideltime-2.3.2.2\"><span class=\"toc-item-num\">2.3.2.2&nbsp;&nbsp;</span>Heideltime</a></span><ul class=\"toc-item\"><li><span><a href=\"#ByDoc\" data-toc-modified-id=\"ByDoc-2.3.2.2.1\"><span class=\"toc-item-num\">2.3.2.2.1&nbsp;&nbsp;</span>ByDoc</a></span></li><li><span><a href=\"#BySentence\" data-toc-modified-id=\"BySentence-2.3.2.2.2\"><span class=\"toc-item-num\">2.3.2.2.2&nbsp;&nbsp;</span>BySentence</a></span></li></ul></li></ul></li><li><span><a href=\"#Code---Multi-Docs\" data-toc-modified-id=\"Code---Multi-Docs-2.3.3\"><span class=\"toc-item-num\">2.3.3&nbsp;&nbsp;</span>Code - Multi Docs</a></span><ul class=\"toc-item\"><li><span><a href=\"#rule-based\" data-toc-modified-id=\"rule-based-2.3.3.1\"><span class=\"toc-item-num\">2.3.3.1&nbsp;&nbsp;</span>rule-based</a></span><ul class=\"toc-item\"><li><span><a href=\"#ByCorpus\" data-toc-modified-id=\"ByCorpus-2.3.3.1.1\"><span class=\"toc-item-num\">2.3.3.1.1&nbsp;&nbsp;</span>ByCorpus</a></span></li><li><span><a href=\"#ByDoc\" data-toc-modified-id=\"ByDoc-2.3.3.1.2\"><span class=\"toc-item-num\">2.3.3.1.2&nbsp;&nbsp;</span>ByDoc</a></span></li><li><span><a href=\"#ByDocSentence\" data-toc-modified-id=\"ByDocSentence-2.3.3.1.3\"><span class=\"toc-item-num\">2.3.3.1.3&nbsp;&nbsp;</span>ByDocSentence</a></span></li></ul></li><li><span><a href=\"#Heideltime\" data-toc-modified-id=\"Heideltime-2.3.3.2\"><span class=\"toc-item-num\">2.3.3.2&nbsp;&nbsp;</span>Heideltime</a></span><ul class=\"toc-item\"><li><span><a href=\"#ByCorpus\" data-toc-modified-id=\"ByCorpus-2.3.3.2.1\"><span class=\"toc-item-num\">2.3.3.2.1&nbsp;&nbsp;</span>ByCorpus</a></span></li><li><span><a href=\"#ByDoc\" data-toc-modified-id=\"ByDoc-2.3.3.2.2\"><span class=\"toc-item-num\">2.3.3.2.2&nbsp;&nbsp;</span>ByDoc</a></span></li><li><span><a href=\"#ByDocSentence\" data-toc-modified-id=\"ByDocSentence-2.3.3.2.3\"><span class=\"toc-item-num\">2.3.3.2.3&nbsp;&nbsp;</span>ByDocSentence</a></span></li></ul></li></ul></li></ul></li></ul></li><li><span><a href=\"#Related-Projects\" data-toc-modified-id=\"Related-Projects-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Related Projects</a></span></li><li><span><a href=\"#Awards\" data-toc-modified-id=\"Awards-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Awards</a></span></li><li><span><a href=\"#References\" data-toc-modified-id=\"References-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>References</a></span><ul class=\"toc-item\"><li><span><a href=\"#Time-Matters\" data-toc-modified-id=\"Time-Matters-5.1\"><span class=\"toc-item-num\">5.1&nbsp;&nbsp;</span>Time-Matters</a></span></li><li><span><a href=\"#YAKE!\" data-toc-modified-id=\"YAKE!-5.2\"><span class=\"toc-item-num\">5.2&nbsp;&nbsp;</span>YAKE!</a></span></li><li><span><a href=\"#InfoSimba\" data-toc-modified-id=\"InfoSimba-5.3\"><span class=\"toc-item-num\">5.3&nbsp;&nbsp;</span>InfoSimba</a></span></li><li><span><a href=\"#Heideltime\" data-toc-modified-id=\"Heideltime-5.4\"><span class=\"toc-item-num\">5.4&nbsp;&nbsp;</span>Heideltime</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Time-Matters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is Time-Matters?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time matters is a [python package](https://github.com/LIAAD/Time-Matters) that aims to score the relevance of temporal expressions found within a text (single document: Time-Matters-SingleDoc) or a set of texts (multiple documents: Time-Matters-MultipleDocs).\n",
    "\n",
    " - The first, aims to determine the relevance of temporal expressions within a single document.\n",
    "\n",
    " - The latter, aims to determine the relevance of temporal expressions within multiple documents."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Who developed this package?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time matters is the result of a research conducted by Ricardo Campos during his [PhD](http://www.ccc.ipt.pt/~ricardo/ficheiros/PhDThesis_RCampos.pdf) at the [University of Porto](https://www.up.pt/). The algorithm, initially implemented in C#, has been made available as a Python package by [Jorge Mendes](https://github.com/JMendes1995) under the supervision of [Professor Ricardo Campos](http://www.ccc.ipt.pt/~ricardo/) in the scope of the Final Project of the Computer Science degree of the [Polytechnic Institute of Tomar](http://portal2.ipt.pt/), Portugal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Main Reference:\n",
    "- Campos, R., Dias, G., Jorge, A. and Nunes, C. (2017). Identifying Top Relevant Dates for Implicit Time Sensitive Queries. In Information Retrieval Journal. Springer, Vol 20(4), pp 363-398 [[pdf]](https://link.springer.com/article/10.1007/s10791-017-9302-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rationale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our assumption is that the relevance of a candidate date (d<sub>j</sub>) may be determined with regards to the relevant terms (W<sub>j</sub><sup>\\*</sup>) that it co-occurs with in a given context (where a context can be a window of _n_ terms in a sentence, the sentence itself, or even a corpus of documents in case we are talking about a collection of multiple documents). That is: the more a given candidate date (d<sub>j</sub>) is correlated with the most relevant keywords (W<sub>j</sub><sup>\\*</sup>) of a document (or documents), the more relevant the candidate date is."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How does it works?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to know more about Time-Matters please refer to this short [guide](https://github.com/LIAAD/Time-Matters/wiki) or to the following list of [publications](https://github.com/LIAAD/Time-Matters#Publications)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Where can I find Time-Matters?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Time-Matters` can be found as a standalone installation on [github](https://github.com/LIAAD/Time-Matters), as a docker [image](https://hub.docker.com/r/liaad/time-matters) and as an API [http://time-matters.inesctec.pt/api]."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Package"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting Relevant Dates from Single Documents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Usage (Python)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time-Matters-SingleDoc aims to score temporal expressions found within a single text. Given an identified temporal expression it offers the user two scoring options:\n",
    "\n",
    "- <b>ByDoc</b>: it retrieves a unique <b>single</b> score for each temporal expression found in the document, regardless it occurs multiple times in different parts of the text, that is, multiple occurrences of a temporal expression in different sentences (e.g., 2019....... 2019), will always return the same score (e.g., 0.92);\n",
    "\n",
    "- <b>BySentence</b>: to retrieve a <b>multiple</b> (eventually different) score for each occurrence of a temporal expression found in the document, that is, multiple occurrences of a temporal expression in different sentences (e.g., 2019....... 2019), will return multiple (eventually different) scores (e.g., 0.92 for the occurrence of 2019 in sentence 1; and 0.77 for the occurrence of 2019 in sentence 2); "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While the first one evaluates the score of a given candidate date in the context of a text, with regards to all the relevant keywords that it co-occurs with (regardless if it's on sentence 1 or 2), the second, evaluates the score of a given candidate date with regards to the sentences where it occurs (thus taking into account only the relevant keywords of each sentence (within the search space defined))."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How to work with each one will be explained next. But before, both the libraries, as well as the text, need to be imported."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Time_Matters_SingleDoc import Time_Matters_SingleDoc\n",
    "\n",
    "text=\"2011 Haiti Earthquake Anniversary. As of 2010 (see 1500 photos here), the following major earthquakes \"\\\n",
    "    \"have been recorded in Haiti. The first great earthquake mentioned in histories of Haiti occurred in \"\\\n",
    "    \"1564 in what was still the Spanish colony. It destroyed Concepción de la Vega. On January 12, 2010, \"\\\n",
    "    \"a massive earthquake struck the nation of Haiti, causing catastrophic damage inside and around the \"\\\n",
    "    \"capital city of Port-au-Prince. On the first anniversary of the earthquake, 12 January 2011, \"\\\n",
    "    \"Haitian Prime Minister Jean-Max Bellerive said the death toll from the quake in 2010 was more \"\\\n",
    "    \"than 316,000, raising the figures in 2010 from previous estimates. I immediately flashed back to the afternoon \"\\\n",
    "    \"of February 11, 1975 when, on my car radio, I first heard the news. Yesterday...\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The structure of the score depends on the type of extraction considered: `ByDoc` or `BySentence`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### ByDoc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting temporal scores by doc is possible through the following code. This configuration assumes \"py_heideltime\" as default temporal tagger (more about this [here](https://github.com/LIAAD/wiki/How-to-use-Time-Matters-SingleDoc#Temporal-Expressions)), \"ByDoc\" as the default score_type and the default parameters of time_matters. In this configuration, a single score will be retrieved for a temporal expression regardless it occurs in different sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = Time_Matters_SingleDoc(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output is a dictionary where the key is the normalized temporal expression and the value is a list with two positions. The first is the score of the temporal expression. The second is a list of the instances of the temporal expression (as they were found in the text). Example: `'2011-01-12': [0.5, ['2011-01-12', '12 January 2011']],`, means that the normalized temporal expression `2011-01-12` has a score of 0.5 and occurs twice in the text. The first time as `2011-01-12`, and the second time as `12 January 2011`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Score = results[0]\n",
    "Score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you are only interested in accessing the keys and the scores run the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for TempExpr in Score:\n",
    "    print(f'{TempExpr}; {Score[TempExpr][0]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### BySentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting temporal scores by sentence is possible through the following code. This configuration assumes \"py_heideltime\" as default temporal tagger (more about this [here](https://github.com/LIAAD/wiki/How-to-use-Time-Matters-SingleDoc#Temporal-Expressions), \"BySentence\" as the score_type and the default parameters of time_matters. In this configuration, multiple occurrences of a temporal expression in different sentences (e.g., \"As of 2010...\"; \"...the quake in 2010 was...\"), will return multiple (eventually different) scores (e.g., 0.2 for its occurrence in sentence 1; and 0.982 for its occurrence on the other sentence)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = Time_Matters_SingleDoc(text, score_type='BySentence')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output is a dictionary where the key is the normalized temporal expression and the value is a dictionary (where the key is the sentenceID and the value is a list with two positions. The first is the score of the temporal expression in that particular sentence. The second is a list of the instances of the temporal expression (as they were found in the text in that particular sentence). Example: `{'2010': {1: [0.2, ['2010']], 5: [0.983, ['2010', '2010']]}}`, means that the normalized temporal expression `2010` has a score of 0.2 in the sentence with ID 1, and a score of 0.983 in the sentence with ID 5 (where it occurs two times)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Score = results[0]\n",
    "Score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you are only interested in accessing the keys and the scores run the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for TempExpr in Score:\n",
    "    print(f'{TempExpr}')\n",
    "    for sentenceID in Score[TempExpr]:\n",
    "        print(f'\\t\\t sentenceID = {sentenceID}; score = {Score[TempExpr][sentenceID][0]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or the following code if, for each temporal expression found, you want to reverse order by score:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for TempExpr in Score:\n",
    "    print(f'{TempExpr}')\n",
    "    for item in sorted(Score[TempExpr].items(), key = lambda x: x[1][0],reverse=True):\n",
    "        print(f'\\t\\t sentenceID = {item[0]}; score = {item[1][0]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Temporal Expressions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- <b>TempExpressions</b>:  A list of tuples, each having two positions. The first is the normalized temporal expression. The second is the temporal expression as it was found in the text. The order in which the elements appear in the list, reflect the order of the temporal expressions in the text. Example: `[('1975-02-11TAF', 'the afternoon of February 11, 1975'),..]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TempExpressions = results[1]\n",
    "TempExpressions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Relevant Keywords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- <b>RelevantKWs</b>: a dictionary of the relevant keywords (and corresponding scores). In our algorithm, keywords are detected by [YAKE!](https://github.com/LIAAD/yake). If you want to know more about the role of YAKE! in Time-Matters, please refer to the following [link](https://github.com/LIAAD/Time-Matters#Text-Representation). Example: `{'haiti': 0.03, 'haiti earthquake': 0.07}` means that the tokens `haiti` and `haiti earthquake` were determined as relevant keywords by YAKE! keyword extractor with the scores 0.03 and 0.07 (the lower the score the more relevant the keyword is)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RelevantKWs = results[2]\n",
    "RelevantKWs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Text Normalized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- <b>TextNormalized</b>: A normalized version of the text, a string, where temporal expressions are marked with the tag `<d>` and relevant keywords with the tag `<kw>`. Example: `As of <d>2010</d> (see 1500 photos here), the following major earthquakes have been recorded in <kw>haiti</kw>.`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TextNormalized = results[3]\n",
    "TextNormalized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Text Tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- <b>TextTokens</b>: A list of the text tokens. Tokens that are temporal expressions are marked with the tag `<d>`, whereas relevant keywords are marked with the tag `<kw>`. Example: `['As', 'of', '<d>2010</d>', 'see', '1500',...]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TextTokens = results[4]\n",
    "TextTokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Sentences Normalized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- <b>SentencesNormalized</b>: A normalized version of the text by sentence, that is a list of lists (position 0 of the list corresponds to sentence 0, etc). Temporal expressions found in the text are marked with the tag `<d>` while relevant keywords are marked with the tag `<kw>`; Example: `[..., 'As of <d>2010</d> (see 1500 photos here), the following major earthquakes have been recorded in <kw>haiti</kw>.',...]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SentencesNormalized = results[5]\n",
    "SentencesNormalized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Sentences Tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- <b>SentencesTokens</b>:  A list of the text tokens by sentence, that is a list of lists (position 0 of the list gives the tokens of sentence 0, etc). Tokens that are temporal expressions are marked with the tag `<d>`, whereas relevant keywords are marked with the tag `<kw>`. Example: `[[...,..], ['As', 'of', '<d>2010</d>', 'see', '1500',...], [...,..],]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SentencesTokens = results[6]\n",
    "SentencesTokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Optional Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apart from the *score_type* (ByDoc and BySentence) there are also parameters regarding the *temporal_tagger* and *time_matters*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Temporal Tagger"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While 'py_heideltime' is the default temporal tagger, a 'rule_based' approach can be used instead. In the following, we assume the default parameters of the rule-based approach, that is: date_granularity is \"full\" (highest possible granularity detected will be retrieved), begin_date is 0 and end_date is 2100 which means that all the dates within this range will be retrieved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = Time_Matters_SingleDoc(text, temporal_tagger=['rule_based'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = results[0]\n",
    "score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead, we can run the following code to define `year` as the default granularity and a `begin` and `end date`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = Time_Matters_SingleDoc(text, temporal_tagger=['rule_based', 'year', 2000, 2011])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = results[0]\n",
    "score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition, a few other parameters are available to `py_heideltime`, namely:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `language`: <b>English</b> - default; <b>Portuguese</b>; <b>Spanish</b>; <b>Germany</b>; <b>Dutch</b>; <b>Italian</b>;  <b>French</b>, <b>Vietnamese</b>, <b>Arabic</b>, <b>Chinese</b>, <b>Russian</b>, <b>Croatian</b> and <b>Estonian</b>;\n",
    "- `date granularity`: <b>\"full\"</b>  - default (Highest possible granularity detected will be retrieved); <b>\"year\"</b> (YYYY will be retrieved); <b>\"month\"</b> (YYYY-MM will be retrieved); <b>\"day\"</b> (YYYY-MM-DD will be retrieved). Note that this parameter can also be used with the rule_based model.\n",
    "- `document type` <b>\"news\"</b>  - default (news-style documents); <b>\"narrative\"</b> (narrative-style documents (e.g., Wikipedia articles)); <b>\"colloquial\"</b> (English colloquial (e.g., Tweets and SMS)); <b>\"scientific\"</b> (scientific articles (e.g., clinical trails))\n",
    "- `document creation time`: in the format <b>YYYY-MM-DD</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following we consider the `English` language, `year` as date granularity (which means that dates will be reduced to years), `news` as document type, and `2009-01-01` as document creation time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = Time_Matters_SingleDoc(text, temporal_tagger=['py_heideltime', 'English', 'year', 'news', '2009-01-01'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Naturally, the results will be different than those obtained when using the \"full\" option for the date granularity, as \"year\" will join different instances of the same year together (e.g., `{'2011': [0.981, ['2011', '12 January 2011']],..}`)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's interisting to note, for instance, that the cluster `2011` consists of two dates, and that the date `Yesterday` has been mapped to 2008 (as the date `2009-01-01` has been given as the document creation time)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Score = results[0]\n",
    "Score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Time Matters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As for time-matters the following paramaters can be defined:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **n-gram**: maximum number of terms a keyword might have. Default value is *1* (but any value > 0 is considered. For instance n = 1 means that single tokens such as \"keyword\" can be considered; instead n = 2 means that \"keyword\" but also \"keyword extractor\" can be considered). More about this [here](https://github.com/LIAAD/Time-Matters#Text-Representation) and [here](https://github.com/LIAAD/Time-Matters#Relevant-Keywords). \n",
    "- **num_of_keywords**: number of YAKE! keywords to extract from the text. Default value is *10* (but any value > 0 is considered) meaning that the system will extract 10 relevant keywords from the text. More about this [here](https://github.com/LIAAD/Time-Matters#Text-Representation) and [here](https://github.com/LIAAD/Time-Matters#Relevant-Keywords). \n",
    "- **n_contextual_window**: defines the n-contextual window distance. Default value is \"*full_sentence*\" (but a n-window where n > 0 can be considered as alternative), that is, the system will look for co-occurrences between terms that occur within the search space of a sentence; More about this [here](https://github.com/LIAAD/Time-Matters#Computing-Dice).\n",
    "- **N**: size of the context vector for X and Y at InfoSimba. Default value is '*max*' (but any value > 0 is considered) meaning that the context vector should have the maximum number of n-terms co-occurring with X (likewise with Y). More about this [here](https://github.com/LIAAD/Time-Matters#Context-Vectors).\n",
    "- **TH**: minimum threshold value from which terms are eligible to the context vector X and Y at InfoSimba. Default value is *0.05* (but any value > 0 is considered) meaning that any terms co-occuring between them with a DICE similarity value > 0.05 are eligible for the n-size vector. More about this [here](https://github.com/LIAAD/Time-Matters#Context-Vectors)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code assumes the default parameters of the `temporal_tagger` and specifies the five parameters (also the default ones) for time_matters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = Time_Matters_SingleDoc(text, time_matters=[1, 10, 'full_sentence', 'max', 0.05])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More interistingly is that if we consider a different n-gram for the keywords. In the following we consider n = 3, and num_of_keywords = 20."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = Time_Matters_SingleDoc(text, time_matters=[3, 20, 'full_sentence', 'max', 0.05])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Score = results[0]\n",
    "Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RelevantKWs = results[2]\n",
    "RelevantKWs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TextNormalized = results[3]\n",
    "TextNormalized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Debug"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also offer the user a debug mode where users can access a more detailed version of the results. Thus in addition to the fields already explained before we also make available the InvertedIndex, the DiceMatrix and the ExecutionTime."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = Time_Matters_SingleDoc(text, debug_mode=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Inverted Index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- <b>InvertedIndex</b>: An inverted index of the document, most notably of its relevant keywords and temporal expressions. As other inverted indexes it follows the following dictionary structure: `{'term' : [SF, TotFreq, {SentenceID : [Freq, [Offsets]]}]`, where `SF` is the `Sentence Frequency`, `TotFreq` is the `total frequency` of the term, `SentenceID` is the `ID of the sentence` (knowing that IDs start on 0), `Freq` is the frequency of the term is that sentence and `[Offsets]` is a list of offsets, that is, a list of the position(s) where the term appears in the text. For instance, a term with the following structure `'2010': [2, 3, {1: [1, [6]], 5: [2, [90, 100]]}]` means that it has 3 occurrences in 2 different sentences. In the sentence with ID 1, it occurs 1 time in position 6. In sentence with ID 5, it occurs 2 times in position 90 and 100. Please note that positions are numbered sequentially from the firt to the last token of the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "InvertedIndex = results[7]\n",
    "InvertedIndex"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we look at the InvertedIndex we can observe, for instance that, `2010` occurs three times in position 6, 90 and 100. This can be confirmed in TextTokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TextTokens = results[4]\n",
    "print(TextTokens[6])\n",
    "print(TextTokens[90])\n",
    "print(TextTokens[100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also observe that it occurs on sentences 1 and 5, as can be confirmed in SentencesNormalized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SentencesNormalized = results[5]\n",
    "print(SentencesNormalized[1])\n",
    "print(\"\\n\")\n",
    "print(SentencesNormalized[5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Dice Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- <b>DicMatrix</b>: It retrieves (in pandas format) the DICE matrix between each term according to the n-contextual window distance defined. For instance, a DICE similarity of 1 between `prime` and `minister` means that, whenever each of these terms occur, they always occur together. If you want to know more about the role of DICE in our algorithm please refer to this [link](https://github.com/LIAAD/Time-Matters#Computing-Dice)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DiceMatrix = results[8]\n",
    "DiceMatrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Execution Time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- <b>ExecutionTime</b>: It retrieves information about the processing times of our algorithm, in particular, of the `TotalTime` required to execute the algorithm, but also of each of its most important components, namely: `heideltime_processing`, `py_heideltime_text_normalization`, `keyword_text_normalization`, `YAKE`, `InvertedIndex`, `DICEMatrix` and `GTE`. As it can be observed from the example, most of the time is consumed by the `py_heideltime` component (which entails the heideltime_processing and the text_normalization process, that is, the tagging of the text with the <d> tag)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ExecutionTime = results[9]\n",
    "ExecutionTime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Usage (Command Line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to know how to execute Time-Matters on the command line please refer to this [link](https://github.com/LIAAD/Time-Matters/wiki/How-to-use-Time-Matters-SingleDoc#Cli)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting Relevant Dates from Multiple Documents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Usage (Python)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time-Matters-MultipleDocs aims to score temporal expressions found within multiple texts. Given an identified temporal expression it offers the user three scoring options:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- <b>ByCorpus</b>: it retrieves a unique <b>single</b> score for each temporal expression found in the corpus of documents, regardless it occurs multiple times in different documents, that is, multiple occurrences of a temporal expression in different documents, will always return the same score (e.g., 0.92);\n",
    "- <b>ByDoc</b>: to retrieve a <b>multiple</b> (eventually different) score for each occurrence of a temporal expression found in the set of documents, that is, multiple occurrences of a temporal expression in different documents, will return multiple (eventually different) scores (e.g., 0.92 for the occurrence of 2019 in document 1; and 0.77 for the occurrence of 2019 in document 2);\n",
    "- <b>ByDocSentence</b>: to retrieve a multiple (eventually different) score for each occurrence of a temporal expression found in a given document, that is, multiple occurrences of a temporal expression in different sentences (e.g., 2019....... 2019) of a document, will return <b>multiple</b> (eventually different) scores (e.g., 0.92 for the occurrence of 2019 in sentence 1 of document 1; and 0.77 for the occurrence of 2019 in sentence 2 of document 1);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While the first one evaluates the score of a given candidate date in the context of a corpus of texts, with regards to all the relevant keywords that it co-occurs with (regardless if it's on document 1 or document 2), the second, evaluates the score of a given candidate date with regards to the documents where it occurs (thus taking into account only the relevant keywords of each document (within the search space defined)). Finally, the third evaluates the score of a given candidate date with regards to the documents and sentences where it occurs (thus taking into account only the relevant keywords of each sentence of a given document (within the search space defined))."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How to work with each one will be explained next. Before that, we explain how to import the libraries and a set of text documents. We suggest you to play with your own texts, or in alternative, to download a set of 28 documents ([MultiDocTexts.zip](https://github.com/LIAAD/Time-Matters/MultiDocTexts.zip)) that we make available in this git as a running example. These documents were collected in November 2016 by issuing the query \"[Boston Marathon Bombing](https://en.wikipedia.org/wiki/Boston_Marathon_bombing)\" on Bing Search Engine. The Diffbot Article API was then used to collect the full text of the top-50 web pages retrieved by Bing. We ended up with 28 documents, as some of them didn't have any useful text."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In any case, if you want to use the following code, don't forget to put the texts under a folder named `data/MultiDocTexts`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Time_Matters_MultipleDocs import Time_Matters_MultipleDocs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "path = 'data/MultiDocTexts'\n",
    "ListOfDocs = []\n",
    "for file in os.listdir (path) :\n",
    "    with open(os.path.join(path, file),'r', encoding=\"cp1252\") as f:\n",
    "        txt = f.read()\n",
    "        ListOfDocs.append(txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(ListOfDocs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The structure of the score depends on the type of extraction considered: `ByCorpus`, `ByDoc` or `ByDocSentence`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### ByCorpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting temporal scores by a corpus of documents is possible through the following code: `results = Time_Matters_MultipleDocs(ListOfDocs)`. This configuration assumes \"py_heideltime\" as the default temporal tagger (more about this [here](https://github.com/LIAAD/wiki/How-to-use-Time-Matters-MultipleDocs#Temporal-Expressions)), \"ByCorpus\" as the default score_type and the default parameters of time_matters. In this configuration, a single score will be retrieved for a temporal expression regardless it occurs in different documents."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running this code, however, will take a considerable amount of time (depending on the PC used) as Heideltime temporal tagger will be running on top of 28 texts. If you want a quicker solution (though not effective) you should use a rule-based approach instead (more about this on the Optional Parameters section). Also letting `py_heideltime` getting all the possible temporal expressions from the text might become too cumbersome. For that reason, we opt to set the date granularity to year and the document timestamp to ´2013-04-15´ (the date of the Boston marathon bombings)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = Time_Matters_MultipleDocs(ListOfDocs, temporal_tagger=['py_heideltime', 'English', 'year', 'news', '2013-04-15'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output is a dictionary where the key is the normalized temporal expression and the value is a list with two positions. The first is the score of the temporal expression. The second is a dictionary of the instances of the temporal expression (as they were found in each document). Example: `{'2011-01-12': [1.0, {0: ['2011-01-12', '12 January 2011'], 6: ['2011-01-12']}]}`, means that the normalized temporal expression `2011-01-12` has a score of 1 and occurs twice (the first time as `2011-01-12`, and the second time as `12 January 2011`) in document 0 and one time (as '2011-01-12') in document 6. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Score = results[0]\n",
    "Score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you are only interested in accessing the keys and the scores run the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for TempExpr in Score:\n",
    "    print(f'{TempExpr}; {Score[TempExpr][0]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### ByDoc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting temporal scores by document is possible through the following code. This configuration is set to consider \"py_heideltime\" as the default temporal tagger (more about this [here](https://github.com/LIAAD/wiki/How-to-use-Time-Matters-MultipleDocs#Temporal-Expressions)), \"ByDoc\" as the score_type and the default parameters of time_matters. In this configuration, multiple occurrences of a temporal expression in different documents, will return multiple (eventually different) scores (e.g., 0.92 for the occurrence of 2019 in sentence 1 of document 1; and 0.77 for the occurrence of 2019 in sentence 2 of document 1). Once again, we apply the `year` granularity to avoid getting too many fine-grained temporal expressions. Yet, you are more than welcome to alternatively run the following code: `results = Time_Matters_MultipleDocs(ListOfDocs, score_type='ByDoc')`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = Time_Matters_MultipleDocs(ListOfDocs, score_type='ByDoc', temporal_tagger=['py_heideltime', 'English', 'year', 'news', '2013-04-15'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output is a dictionary where the key is the normalized temporal expression and the value is a dictionary (where the key is the DocID and the value is a list with two positions. The first is the score of the temporal expression in that particular document. The second is a list of the instances of the temporal expression (as they were found in the text in that particular document). Example: `{'2010': {1: [0.2, ['2010']], 5: [0.983, ['2010', '2010']]}}`, means that the normalized temporal expression `2010` has a score of 0.2 in the document with ID 1, and a score of 0.983 in the document with ID 5 (where it occurs two times)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Score = results[0]\n",
    "Score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you are only interested in accessing the keys and the scores run the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for TempExpr in Score:\n",
    "    print(f'{TempExpr}')\n",
    "    for docID in Score[TempExpr]:\n",
    "        print(f'\\t docID = {docID}; score = {Score[TempExpr][docID][0]}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or the following code if, for each temporal expression found, you want to reverse order by score:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for TempExpr in Score:\n",
    "    print(f'{TempExpr}')\n",
    "    for item in sorted(Score[TempExpr].items(), key = lambda x: x[1][0],reverse=True):\n",
    "        print(f'\\t docID = {item[0]}; score = {item[1][0]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### ByDocSentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting temporal scores by document & sentence is possible through the following code. This configuration is set to consider \"py_heideltime\" as the default temporal tagger (more about this [here](https://github.com/LIAAD/wiki/How-to-use-Time-Matters-MultipleDocs#Temporal-Expressions)), \"ByDoc&Sentence\" as the score_type and the default parameters of time_matters. In this configuration, multiple occurrences of a temporal expression in different sentences of a given document, will return multiple (eventually different) scores (e.g., 0.2 for its occurrence in document 1; and 0.982 for its occurrence in document 2). Once again, we apply the `year` granularity to avoid getting too many fine-grained temporal expressions. Yet, you are more than welcome to alternatively run the following code: `results = Time_Matters_MultipleDocs(ListOfDocs, score_type='ByDocSentence')`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = Time_Matters_MultipleDocs(ListOfDocs, score_type='ByDocSentence', temporal_tagger=['py_heideltime', 'English', 'year', 'news', '2013-04-15'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output is a dictionary where the key is the normalized temporal expression and the value is a dictionary (where the key is the DocID and the value is a new dictionary (where the key is the sentenceID and the value is list with two positions. The first is the score of the temporal expression in that particular sentence. The second is a list of the instances of the temporal expression (as they were found in the text in that particular setencent of that document)). Example: `{'2011': {0: {5: [0.983, ['2010', '2010']], {6: [0.183, ['2010']]}}`, means that the normalized temporal expression `2011` has a score of 0.983 in the sentence with ID 5 (where it occurs twice) of docID 0, and a score of 0.183 in the sentence with ID 6 of docID 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Score = results[0]\n",
    "Score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you are only interested in accessing the keys and the scores run the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for TempExpr in Score:\n",
    "    print(f'{TempExpr}')\n",
    "    for docID in Score[TempExpr]:\n",
    "        print(f'\\t docID = {docID}')\n",
    "        for sentenceID in Score[TempExpr][docID]:\n",
    "            print(f'\\t\\t sentenceID = {sentenceID}; score = {Score[TempExpr][docID][sentenceID][0]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or the following code if, for each temporal expression found, you want to reverse order by score:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for TempExpr in Score:\n",
    "    print(f'{TempExpr}')\n",
    "    for docID in Score[TempExpr]:\n",
    "        print(f'\\t docID = {docID}')\n",
    "        for item in sorted(Score[TempExpr][docID].items(), key = lambda x: x[1][0],reverse=True):\n",
    "            print(f'\\t \\t sentenceID = {item[0]}; score = {item[1][0]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Temporal Expressions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- <b>TempExpressions</b>:  A dictionary, where the key is the docID and the value is a list of tuples, each having two positions. The first is the normalized temporal expression. The second is the temporal expression as it was found in the text. The order in which the elements appear in the list, reflect the order of the temporal expressions in the text. Example: `{0: [('1975-02-11TAF', 'the afternoon of February 11, 1975'),..]}`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TempExpressions = results[1]\n",
    "TempExpressions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Relevant Keywords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- <b>RelevantKWs</b>: a dictionary where the key is the docID and the value is a dictionary of the relevant keywords (and corresponding scores). In our algorithm, keywords are detected by [YAKE!](https://github.com/LIAAD/yake). If you want to know more about the role of YAKE! in Time-Matters, please refer to the following [link](https://github.com/LIAAD/Time-Matters#Text-Representation). Example: `{0: {'haiti': 0.03, 'haiti earthquake': 0.07}}` means that the tokens `haiti` and `haiti earthquake` were determined as relevant keywords by YAKE! keyword extractor with the scores 0.03 and 0.07 (the lower the score the more relevant the keyword is) in docID 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RelevantKWs = results[2]\n",
    "RelevantKWs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Text Normalized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- <b>TextNormalized</b>: A normalized version of the text, a dictionary, where the key is the docID and the value is a string, where temporal expressions are marked with the tag `<d>` and relevant keywords with the tag `<kw>`. Example: `{0: 'As of <d>2010</d> (see 1500 photos here), the following major earthquakes have been recorded in <kw>haiti</kw>.'}`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TextNormalized = results[3]\n",
    "TextNormalized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Text Tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- <b>TextTokens</b>: A dictionary where the key is the docID and the value is a list of the text tokens. Tokens that are temporal expressions are marked with the tag `<d>`, whereas relevant keywords are marked with the tag `<kw>`. Example: `{0: ['As', 'of', '<d>2010</d>', 'see', '1500',...]}`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TextTokens = results[4]\n",
    "TextTokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Sentences Normalized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- <b>SentencesNormalized</b>: A dictionary, where the key is the docID and the value is a list of the normalized version of the sentence text (position 0 of the list corresponds to sentence 0, etc). Temporal expressions found in the text are marked with the tag `<d>` while relevant keywords are marked with the tag `<kw>`; Example: `{0: [..., 'As of <d>2010</d> (see 1500 photos here), the following major earthquakes have been recorded in <kw>haiti</kw>.',...]}`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SentencesNormalized = results[5]\n",
    "SentencesNormalized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Sentences Tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- <b>SentencesTokens</b>:  A dictionary, where the key is the docID and the value is a list of the text tokens by sentence, that is a list of lists (position 0 of the list gives the tokens of sentence 0, etc). Tokens that are temporal expressions are marked with the tag `<d>`, whereas relevant keywords are marked with the tag `<kw>`. Example: `{0: [[...,..], ['As', 'of', '<d>2010</d>', 'see', '1500',...], [...,..],]}`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SentencesTokens = results[6]\n",
    "SentencesTokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Optional Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apart from the *score_type* (ByCorpus, ByDoc and ByDocSentence) there are also parameters regarding the *temporal_tagger* and *time_matters*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Temporal Tagger"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While 'py_heideltime' is the default temporal tagger, a 'rule_based' approach can be used instead. In the following, we assume the default parameters of the rule-based approach, that is: date_granularity is \"full\" (highest possible granularity detected will be retrieved), begin_date is 0 and end_date is 2100 which means that all the dates within this range will be retrieved. Instead, we can specify a more fine-grained granularity, such as `year` and a `begin` and `end date` which would result in the following code: `results = Time_Matters_SingleDoc(text, temporal_tagger=['rule_based', 'year', 2000, 2011])`. However, in the following code, we resort to the default parameter values of the rule-based approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = Time_Matters_MultipleDocs(ListOfDocs, temporal_tagger=['rule_based'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Score = results[0]\n",
    "Score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you are only interested in accessing the keys and the scores run the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for TempExpr in Score:\n",
    "    print(f'{TempExpr}; {Score[TempExpr][0]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition, a few other parameters (already experienced before) are available to `py_heideltime`, namely:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `language`: <b>English</b> - default; <b>Portuguese</b>; <b>Spanish</b>; <b>Germany</b>; <b>Dutch</b>; <b>Italian</b>;  <b>French</b>, <b>Vietnamese</b>, <b>Arabic</b>, <b>Chinese</b>, <b>Russian</b>, <b>Croatian</b> and <b>Estonian</b>;\n",
    "- `date granularity`: <b>\"full\"</b>  - default (Highest possible granularity detected will be retrieved); <b>\"year\"</b> (YYYY will be retrieved); <b>\"month\"</b> (YYYY-MM will be retrieved); <b>\"day\"</b> (YYYY-MM-DD will be retrieved). Note that this parameter can also be used with the rule_based model.\n",
    "- `document type` <b>\"news\"</b>  - default (news-style documents); <b>\"narrative\"</b> (narrative-style documents (e.g., Wikipedia articles)); <b>\"colloquial\"</b> (English colloquial (e.g., Tweets and SMS)); <b>\"scientific\"</b> (scientific articles (e.g., clinical trails))\n",
    "- `document creation time`: in the format <b>YYYY-MM-DD</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Time Matters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **n-gram**: maximum number of terms a keyword might have. Default value is *1* (but any value > 0 is considered. For instance n = 1 means that single tokens such as \"keyword\" can be considered; instead n = 2 means that \"keyword\" but also \"keyword extractor\" can be considered). More about this [here](https://github.com/LIAAD/Time-Matters#Text-Representation) and [here](https://github.com/LIAAD/Time-Matters#Relevant-Keywords). \n",
    "- **num_of_keywords**: number of YAKE! keywords to extract from the text. Default value is *10* (but any value > 0 is considered) meaning that the system will extract 10 relevant keywords from the text. More about this [here](https://github.com/LIAAD/Time-Matters#Text-Representation) and [here](https://github.com/LIAAD/Time-Matters#Relevant-Keywords). \n",
    "- **n_contextual_window**: defines the n-contextual window distance. Default value is \"*full_document*\" when the score type is ByCorpus, or \"*full_sentence*\" (but a n-window where n > 0 can be considered as alternative) when the score type is ByDoc or ByDocSentence. More about this [here](https://github.com/LIAAD/Time-Matters#Computing-Dice).\n",
    "- **N**: size of the context vector for X and Y at InfoSimba. Default value is '10' (but any value > 0 is considered). You can also define 'max' meaning that the context vector should have the maximum number of n-terms co-occurring with X (likewise with Y). This option however will require a huge amount of time (depending on the PC) to execute. More about this [here](https://github.com/LIAAD/Time-Matters#Context-Vectors).\n",
    "- **TH**: minimum threshold value from which terms are eligible to the context vector X and Y at InfoSimba. Default value is *0.05* (but any value > 0 is considered) meaning that any terms co-occuring between them with a DICE similarity value > 0.05 are eligible for the n-size vector. More about this [here](https://github.com/LIAAD/Time-Matters#Context-Vectors)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code assumes a score-type of `ByCorpus`, the default parameters of the `temporal_tagger` (such as `py_heideltime`) and specifies the five parameters (also the default ones) for time_matters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = Time_Matters_MultipleDocs(ListOfDocs, time_matters=[1, 10, 'full_document', 10, 0.05])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More interistingly is that if we consider a different n-gram for the keywords. In the following we consider n = 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = Time_Matters_MultipleDocs(ListOfDocs, time_matters=[3, 10, 'full_document', 10, 0.05])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note (before executing the following code) that in this case, we didn't define the granularity to year, thus we will get a huge number of temporal expressions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Score = results[0]\n",
    "Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RelevantKWs = results[2]\n",
    "RelevantKWs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TextNormalized = results[3]\n",
    "TextNormalized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Debug"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also offer the user a debug mode where users can access a more detailed version of the results. Thus in addition to the fields already explained before we also make available the InvertedIndex, the DiceMatrix and the ExecutionTime."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To this regard, we consider the following code with `debug_mode=True`, thus assuming the score_type `ByCorpus`, and the default parameters of `temporal_tagger` (thus with heideltime) and of `time_matters`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = Time_Matters_MultipleDocs(ListOfDocs, debug_mode=True)\n",
    "\n",
    "#likewise:\n",
    "#results = Time_Matters_MultipleDocs(ListOfDocs, score_type='ByCorpus', temporal_tagger=['py_heideltime', 'English', 'year', 'news', '2013-04-15'], time_matters=[1, 10, 'full_document', 10, 0.05], debug_mode=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Score = results[0]\n",
    "Score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Inverted Index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- <b>InvertedIndex</b>: An inverted index of the entire set of documents, most notably of its relevant keywords and temporal expressions. It follows the following dictionary structure: `{'term' : [DF, TotFreq, {DocID : [FreqInDoc, [OffsetsDoc], {SentenceID :  [FreqInSentence, [OffsetsSentence]]}]}]`, where `DF` is the `Document Frequency`, `TotFreq` is the `total frequency` of the term within the entire corpus of documents, `DocID` is the `ID of the document` (knowing that IDs start on 0), `FreqInDoc` is the frequency of the term in the document,  `[OffsetsDoc]` is a list of the document offsets, that is, a list of the position(s) where the term appears in the document, `SentenceID` is the `ID of the sentence`, `FreqInSentence` is the frequency of the term in the sentence, `OffsetsSentence` is a list of the sentence offsets, that is, a list of the position(s) where the term appears in the sentence. For instance, a term with the following structure `'2010': [1, 4, {1 : [4, [6, 13, 20, 27], {0 :  [2, [6, 13]], 1: [2, [20, 27]] }]}]` means that it has 4 occurrences in 1 document, in particular in the document with ID 1, namely in position 6, 13, 20, and 27, the first two occur in sentence ID 0, and the latter in sentence ID 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "InvertedIndex = results[7]\n",
    "InvertedIndex"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we look at the InvertedIndex we can observe, for instance that, `1907` (with the following information: `[1, 2, {16: [2, [82, 154], {2: [1, [82]], 5: [1, [154]]}]}]`) occurs in 1 document only (docId 16), 2 times (in offsets 82 and 154 of DocId 16). The first occurrence is on sentenceID 2, and the second occurrence is on sentenceID 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TextTokens = results[4]\n",
    "print(TextTokens[16][82])\n",
    "print(TextTokens[16][154])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also observe that it occurs on sentences 2 and 5, as can be confirmed in SentencesNormalized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SentencesNormalized = results[5]\n",
    "print(SentencesNormalized[16][2])\n",
    "print(\"\\n\")\n",
    "print(SentencesNormalized[16][5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Dice Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- <b>DicMatrix</b>: It retrieves (in pandas format) the DICE matrix between each term according to the n-contextual window distance defined. For instance, a DICE similarity of 1 between `prime` and `minister` means that, whenever each of these terms occur, they always occur together. If you want to know more about the role of DICE in our algorithm please refer to this [link](https://github.com/LIAAD/Time-Matters#Computing-Dice)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DiceMatrix = results[8]\n",
    "DiceMatrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Execution Time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- <b>ExecutionTime</b>: It retrieves information about the processing times of our algorithm, in particular, of the `TotalTime` required to execute the algorithm, but also of each of its most important components, namely: `heideltime_processing`, `text_normalization`, `YAKE`, `InvertedIndex`, `DICEMatrix` and `GTE`. As it can be observed from the example, most of the time is consumed by the `py_heideltime` component (which entails the heideltime_processing and the text_normalization process, that is, the tagging of the text with the <d> tag)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ExecutionTime = results[9]\n",
    "ExecutionTime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cli - Command Line Interface"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to know how to execute Time-Matters on the command line please refer to this [link](https://github.com/LIAAD/Time-Matters/wiki/How-to-use-Time-Matters-MultipleDocs#Cli)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### apidocs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "http://tm-websuiteapps.ipt.pt/timematters/apidocs ou http://time-matters.inesctec.pt/api"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code - Single Doc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time-Matters Single Document configuration entails `ByDoc` and `BySentence` score with two possible temporal taggers (`rule-based` and `Heideltime`)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### rule-based"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Text input:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "text=\"2011 Haiti Earthquake Anniversary. As of 2010 (see 1500 photos here), the following major earthquakes \"\\\n",
    "    \"have been recorded in Haiti. The first great earthquake mentioned in histories of Haiti occurred in \"\\\n",
    "    \"1564 in what was still the Spanish colony. It destroyed Concepción de la Vega. On January 12, 2010, \"\\\n",
    "    \"a massive earthquake struck the nation of Haiti, causing catastrophic damage inside and around the \"\\\n",
    "    \"capital city of Port-au-Prince. On the first anniversary of the earthquake, 12 January 2011, \"\\\n",
    "    \"Haitian Prime Minister Jean-Max Bellerive said the death toll from the quake in 2010 was more \"\\\n",
    "    \"than 316,000, raising the figures in 2010 from previous estimates. I immediately flashed back to the afternoon \"\\\n",
    "    \"of February 11, 1975 when, on my car radio, I first heard the news. Yesterday...\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### ByDoc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_api = \"https://tm-websuiteapps.ipt.pt/timematters/SingleDoc/RuleBased/api/v1.0/ScoreByDoc\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code defines the parameters, namely the text, which is passed to the endpoint. Default parameters are commented in the code and can be changed whenever appropriate. More detailes about this parameters can be found above in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "payload = {'text': text}\n",
    "#payload = {'text': text, 'ngram': 1, 'num_of_keywords': 10, 'n_contextual_window': 'full_sentence', 'N':'max', 'TH':0.05, 'date_granularity': 'full', 'begin_date': 0, 'end_date': 2100}\n",
    "r = requests.post(url_api, data=payload)\n",
    "print(r.url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code gets the JSon reply. Please check the previous sections if you are interested in playing with the object retrieved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "content = r.json()\n",
    "content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### BySentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_api = \"https://tm-websuiteapps.ipt.pt/timematters/SingleDoc/RuleBased/api/v1.0/ScoreBySentence\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code defines the parameters, namely the text, which is passed to the endpoint. Default parameters are commented in the code and can be changed whenever appropriate. More detailes about this parameters can be found above in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "payload = {'text': text}\n",
    "#payload = {'text': text, 'ngram': 1, 'num_of_keywords': 10, 'n_contextual_window': 'full_sentence', 'N':'max', 'TH':0.05, 'date_granularity': 'full', 'begin_date': 0, 'end_date': 2100}\n",
    "r = requests.post(url_api, data=payload)\n",
    "print(r.url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code gets the JSon reply. Please check the previous sections if you are interested in playing with the object retrieved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "content = r.json()\n",
    "content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Heideltime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Text input:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "text=\"2011 Haiti Earthquake Anniversary. As of 2010 (see 1500 photos here), the following major earthquakes \"\\\n",
    "    \"have been recorded in Haiti. The first great earthquake mentioned in histories of Haiti occurred in \"\\\n",
    "    \"1564 in what was still the Spanish colony. It destroyed Concepción de la Vega. On January 12, 2010, \"\\\n",
    "    \"a massive earthquake struck the nation of Haiti, causing catastrophic damage inside and around the \"\\\n",
    "    \"capital city of Port-au-Prince. On the first anniversary of the earthquake, 12 January 2011, \"\\\n",
    "    \"Haitian Prime Minister Jean-Max Bellerive said the death toll from the quake in 2010 was more \"\\\n",
    "    \"than 316,000, raising the figures in 2010 from previous estimates. I immediately flashed back to the afternoon \"\\\n",
    "    \"of February 11, 1975 when, on my car radio, I first heard the news. Yesterday...\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### ByDoc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_api = \"https://tm-websuiteapps.ipt.pt/timematters/SingleDoc/Heideltime/api/v1.0/ScoreByDoc\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code defines the parameters, namely the text, which is passed to the endpoint. Default parameters are commented in the code and can be changed whenever appropriate. More detailes about this parameters can be found above in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "payload = {'text': text}\n",
    "#payload = {'text': text, 'ngram': 1, 'num_of_keywords': 10, 'n_contextual_window': 'full_sentence', 'N':'max', 'TH':0.05, 'date_granularity': 'full', 'language': 'English', 'document_type': 'news', 'document_creation_time': '2009-01-01'}\n",
    "r = requests.post(url_api, data=payload)\n",
    "print(r.url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code gets the JSon reply. Please check the previous sections if you are interested in playing with the object retrieved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "content = r.json()\n",
    "content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### BySentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_api = \"https://tm-websuiteapps.ipt.pt/timematters/SingleDoc/Heideltime/api/v1.0/ScoreBySentence\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code defines the parameters, namely the text, which is passed to the endpoint. Default parameters are commented in the code and can be changed whenever appropriate. More detailes about this parameters can be found above in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "payload = {'text': text}\n",
    "#payload = {'text': text, 'ngram': 1, 'num_of_keywords': 10, 'n_contextual_window': 'full_sentence', 'N':'max', 'TH':0.05, 'date_granularity': 'full', 'language': 'English', 'document_type': 'news', 'document_creation_time': '2009-01-01'}\n",
    "r = requests.post(url_api, data=payload)\n",
    "print(r.url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code gets the JSon reply. Please check the previous sections if you are interested in playing with the object retrieved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "content = r.json()\n",
    "content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code - Multi Docs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time-Matters Multiple Documents configuration entails `ByCorpus`, `ByDoc` and `BySentence` score with two possible temporal taggers (`rule-based` and `Heideltime`)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### rule-based"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Input List of Documents:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Time_Matters_MultipleDocs import Time_Matters_MultipleDocs\n",
    "import os\n",
    "path = 'data/MultiDocTexts'\n",
    "ListOfDocs = []\n",
    "for file in os.listdir (path) :\n",
    "    with open(os.path.join(path, file),'r') as f:\n",
    "        txt = f.read()\n",
    "        ListOfDocs.append(txt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### ByCorpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_api = \"https://tm-websuiteapps.ipt.pt/timematters/MultiDocs/RuleBased/api/v1.0/ScoreByCorpus\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code defines the parameters, namely the list of documents, which is passed to the endpoint. Default parameters are commented in the code and can be changed whenever appropriate. More detailes about this parameters can be found above in this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that in this case the document list must be converted to a string (via the `json.dumps` code) so that it can be passed to the API via the POST method. Later on the server and through the code `json.loads` the string will be converted back to a document list. Additionally, we have in this call a `typeOfInput` parameter that indicates that texts are passed from a string. This parameter is mostly used to distinguish between programmatic requests (where documents are passed as a string) and APIDocs requests where documents are inserted in zip format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "payload = {'text': json.dumps(ListOfDocs), 'typeOfInput': 'string'}\n",
    "#payload = {'text': json.dumps(ListOfDocs), 'typeOfInput': 'string', 'ngram': 1, 'num_of_keywords': 10, 'n_contextual_window': 'full_document', 'N':10, 'TH':0.05, 'date_granularity': 'full', 'begin_date': 0, 'end_date': 2100}\n",
    "r = requests.post(url_api, data=payload)\n",
    "print(r.url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code gets the JSon reply. Please check the previous sections if you are interested in playing with the object retrieved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "content = r.json()\n",
    "content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### ByDoc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_api = \"https://tm-websuiteapps.ipt.pt/timematters/MultiDocs/RuleBased/api/v1.0/ScoreByDoc\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code defines the parameters, namely the list of documents, which is passed to the endpoint. Default parameters are commented in the code and can be changed whenever appropriate. More detailes about this parameters can be found above in this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that in this case the document list must be converted to a string (via the `json.dumps` code) so that it can be passed to the API via the POST method. Later on the server and through the code `json.loads` the string will be converted back to a document list. Additionally, we have in this call a `typeOfInput` parameter that indicates that texts are passed from a string. This parameter is mostly used to distinguish between programmatic requests (where documents are passed as a string) and APIDocs requests where documents are inserted in zip format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "payload = {'text': json.dumps(ListOfDocs), 'typeOfInput': 'string'}\n",
    "#payload = {'text': json.dumps(ListOfDocs), 'typeOfInput': 'string', 'ngram': 1, 'num_of_keywords': 10, 'n_contextual_window': 'full_sentence', 'N':10, 'TH':0.05, 'date_granularity': 'full', 'begin_date': 0, 'end_date': 2100}\n",
    "r = requests.post(url_api, data=payload)\n",
    "print(r.url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code gets the JSon reply. Please check the previous sections if you are interested in playing with the object retrieved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "content = r.json()\n",
    "content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### ByDocSentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_api = \"https://tm-websuiteapps.ipt.pt/timematters/MultiDocs/RuleBased/api/v1.0/ScoreByDocSentence\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code defines the parameters, namely the list of documents, which is passed to the endpoint. Default parameters are commented in the code and can be changed whenever appropriate. More detailes about this parameters can be found above in this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that in this case the document list must be converted to a string (via the `json.dumps` code) so that it can be passed to the API via the POST method. Later on the server and through the code `json.loads` the string will be converted back to a document list. Additionally, we have in this call a `typeOfInput` parameter that indicates that texts are passed from a string. This parameter is mostly used to distinguish between programmatic requests (where documents are passed as a string) and APIDocs requests where documents are inserted in zip format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "payload = {'text': json.dumps(ListOfDocs), 'typeOfInput': 'string'}\n",
    "#payload = {'text': json.dumps(ListOfDocs), 'typeOfInput': 'string', 'ngram': 1, 'num_of_keywords': 10, 'n_contextual_window': 'full_sentence', 'N':10, 'TH':0.05, 'date_granularity': 'full', 'begin_date': 0, 'end_date': 2100}\n",
    "r = requests.post(url_api, data=payload)\n",
    "print(r.url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code gets the JSon reply. Please check the previous sections if you are interested in playing with the object retrieved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "content = r.json()\n",
    "content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Heideltime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Input List of Documents:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Time_Matters_MultipleDocs import Time_Matters_MultipleDocs\n",
    "import os\n",
    "path = 'data/MultiDocTexts'\n",
    "ListOfDocs = []\n",
    "for file in os.listdir (path) :\n",
    "    with open(os.path.join(path, file),'r') as f:\n",
    "        txt = f.read()\n",
    "        ListOfDocs.append(txt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### ByCorpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_api = \"https://tm-websuiteapps.ipt.pt/timematters/MultiDocs/Heideltime/api/v1.0/ScoreByCorpus\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code defines the parameters, namely the list of documents, which is passed to the endpoint. Default parameters are commented in the code and can be changed whenever appropriate. More detailes about this parameters can be found above in this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that in this case the document list must be converted to a string (via the `json.dumps` code) so that it can be passed to the API via the POST method. Later on the server and through the code `json.loads` the string will be converted back to a document list. Additionally, we have in this call a `typeOfInput` parameter that indicates that texts are passed from a string. This parameter is mostly used to distinguish between programmatic requests (where documents are passed as a string) and APIDocs requests where documents are inserted in zip format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "payload = {'text': json.dumps(ListOfDocs), 'typeOfInput': 'string'}\n",
    "#payload = {'text': json.dumps(ListOfDocs), 'typeOfInput': 'string', 'ngram': 1, 'num_of_keywords': 10, 'n_contextual_window': 'full_document', 'N':10, 'TH':0.05, 'date_granularity': 'full', 'language': 'English', 'document_type': 'news', 'document_creation_time': '2013-04-15'}\n",
    "r = requests.post(url_api, data=payload)\n",
    "print(r.url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code gets the JSon reply. Please check the previous sections if you are interested in playing with the object retrieved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "content = r.json()\n",
    "content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### ByDoc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_api = \"https://tm-websuiteapps.ipt.pt/timematters/MultiDocs/Heideltime/api/v1.0/ScoreByDoc\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code defines the parameters, namely the list of documents, which is passed to the endpoint. Default parameters are commented in the code and can be changed whenever appropriate. More detailes about this parameters can be found above in this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that in this case the document list must be converted to a string (via the `json.dumps` code) so that it can be passed to the API via the POST method. Later on the server and through the code `json.loads` the string will be converted back to a document list. Additionally, we have in this call a `typeOfInput` parameter that indicates that texts are passed from a string. This parameter is mostly used to distinguish between programmatic requests (where documents are passed as a string) and APIDocs requests where documents are inserted in zip format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "payload = {'text': json.dumps(ListOfDocs), 'typeOfInput': 'string'}\n",
    "#payload = {'text': json.dumps(ListOfDocs), 'typeOfInput': 'string', 'ngram': 1, 'num_of_keywords': 10, 'n_contextual_window': 'full_sentence', 'N':10, 'TH':0.05, 'date_granularity': 'full', 'language': 'English', 'document_type': 'news', 'document_creation_time': '2013-04-15'}\n",
    "r = requests.post(url_api, data=payload)\n",
    "print(r.url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code gets the JSon reply. Please check the previous sections if you are interested in playing with the object retrieved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "content = r.json()\n",
    "content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### ByDocSentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_api = \"https://tm-websuiteapps.ipt.pt/timematters/MultiDocs/Heideltime/api/v1.0/ScoreByDocSentence\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code defines the parameters, namely the list of documents, which is passed to the endpoint. Default parameters are commented in the code and can be changed whenever appropriate. More detailes about this parameters can be found above in this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that in this case the document list must be converted to a string (via the `json.dumps` code) so that it can be passed to the API via the POST method. Later on the server and through the code `json.loads` the string will be converted back to a document list. Additionally, we have in this call a `typeOfInput` parameter that indicates that texts are passed from a string. This parameter is mostly used to distinguish between programmatic requests (where documents are passed as a string) and APIDocs requests where documents are inserted in zip format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "payload = {'text': json.dumps(ListOfDocs), 'typeOfInput': 'string'}\n",
    "#payload = {'text': json.dumps(ListOfDocs), 'typeOfInput': 'string', 'ngram': 1, 'num_of_keywords': 10, 'n_contextual_window': 'full_sentence', 'N':10, 'TH':0.05, 'date_granularity': 'full', 'language': 'English', 'document_type': 'news', 'document_creation_time': '2013-04-15'}\n",
    "r = requests.post(url_api, data=payload)\n",
    "print(r.url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code gets the JSon reply. Please check the previous sections if you are interested in playing with the object retrieved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "content = r.json()\n",
    "content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Related Projects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please check [py_rule_based](https://github.com/JMendes1995/py_rule_based) if you are interested in extracting dates by means of a rule-based model solution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please check py_heideltime [github package](https://github.com/JMendes1995/py_heideltime) or [docker image](https://hub.docker.com/r/liaad/py_heideltime) if you are interested in extracting temporal expressions using Heideltime Temporal Tagger."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Awards"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Winner of the [Fraunhofer Portugal Challenge 2013 PhD Contest](https://www.aicos.fraunhofer.pt/en/news_and_events_aicos/news_archive/older_archive/fraunhofer-portugal-challenge-2013-winners.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time-Matters\n",
    "If you use Time-Matters please cite the appropriate paper. In general, this will be:\n",
    "\n",
    "- Campos, R., Dias, G., Jorge, A. and Nunes, C. (2017). Identifying Top Relevant Dates for Implicit Time Sensitive Queries. In Information Retrieval Journal. Springer, Vol 20(4), pp 363-398 [[pdf]](https://link.springer.com/article/10.1007/s10791-017-9302-1)\n",
    "\n",
    "Other Time-Matters related papers may be found here:\n",
    "\n",
    "- Campos, R., Dias, G., Jorge, A. and Nunes, C. (2016). GTE-Rank: a Time-Aware Search Engine to Answer Time-Sensitive Queries. In Information Processing & Management an International Journal. Elsevier, Vol 52(2), pp. 273-298 [[pdf]](https://www.sciencedirect.com/science/article/abs/pii/S0306457315001016)\n",
    "\n",
    "- Campos, R., Dias, G., Jorge, A., and Nunes, C. (2014). GTE-Cluster: A Temporal Search Interface for Implicit Temporal Queries. In M. de Rijke et al. (Eds.), Lecture Notes in Computer Science - Advances in Information Retrieval - 36th European Conference on Information Retrieval (ECIR2014). Amesterdam, Netherlands, 13 - 16 April. (Vol. 8416-2014, pp. 775 - 779) [[pdf]](https://link.springer.com/chapter/10.1007/978-3-319-06028-6_94#page-1)\n",
    "\n",
    "- Campos, R., Jorge, A., Dias, G. and Nunes, C. (2012). Disambiguating Implicit Temporal Queries by Clustering Top Relevant Dates in Web Snippets. In Proceedings of The 2012 IEEE/WIC/ACM International Joint Conferences on Web Intelligence and Intelligent Agent Technologies Macau, China, 04 - 07 December, Vol. 1, pp 1 - 8. IEEE Computer Society Press. [[pdf]](https://ieeexplore.ieee.org/document/6511858?tp=&arnumber=6511858&url=http:%2F%2Fieeexplore.ieee.org%2Fxpls%2Fabs_all.jsp%3Farnumber%3D6511858)\n",
    "\n",
    "### YAKE!\n",
    "YAKE! papers may be found here:\n",
    "\n",
    "- Campos R., Mangaravite V., Pasquali A., Jorge A.M., Nunes C., and Jatowt A. (2020). YAKE! Keyword Extraction from Single Documents using Multiple Local Features. In Information Sciences. Elsevier, Vol 509, pp. 257-289 [pdf](https://linkinghub.elsevier.com/retrieve/pii/S0020025519308588).\n",
    "\n",
    "- Campos R., Mangaravite V., Pasquali A., Jorge A.M., Nunes C., and Jatowt A. (2018). A Text Feature Based Automatic Keyword Extraction Method for Single Documents. In: Pasi G., Piwowarski B., Azzopardi L., Hanbury A. (eds). Advances in Information Retrieval. ECIR 2018 (Grenoble, France. March 26 – 29). Lecture Notes in Computer Science, vol 10772, pp. 684 - 691. [[pdf]](https://link.springer.com/chapter/10.1007/978-3-319-76941-7_63). [<b>ECIR'18 Best Short Paper</b>]\n",
    "\n",
    "- Campos R., Mangaravite V., Pasquali A., Jorge A.M., Nunes C., and Jatowt A. (2018). YAKE! Collection-independent Automatic Keyword Extractor. In: Pasi G., Piwowarski B., Azzopardi L., Hanbury A. (eds). Advances in Information Retrieval. ECIR 2018 (Grenoble, France. March 26 – 29). Lecture Notes in Computer Science, vol 10772, pp. 806 - 810. [[pdf]](https://link.springer.com/chapter/10.1007/978-3-319-76941-7_80)\n",
    "\n",
    "### InfoSimba\n",
    "InfoSimba similarity measure papers may be found here:\n",
    "- Dias, G., Alves, E., & Lopes, J. (2007). Topic Segmentation Algorithms for Text Summarization and Passage Retrieval: An Exhaustive Evaluation. In AAAI 2007: Proceedings of the 22nd Conference on Artificial Intelligence (pp. 1334 - 1340). Vancouver, Canada. July 22 – 26.: AAAI Press.\n",
    "[[pdf]](https://pdfs.semanticscholar.org/b9ef/4f739ae625f753c0ffc687369a6f335c22c1.pdf?_ga=2.179772898.733053942.1561296709-837078907.1557947535)\n",
    "\n",
    "### Heideltime\n",
    "Heideltime papers may be found here:\n",
    "\n",
    "- Strötgen, J., and Gertz, M. (2013). Multilingual and Cross-domain Temporal Tagging. In: Language Resources and Evaluation, 47(3), pp. 269-298. [[pdf]](https://link.springer.com/article/10.1007%2Fs10579-012-9179-y)\n",
    "\n",
    "or [here](https://github.com/HeidelTime/heideltime#Publications)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "261px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
